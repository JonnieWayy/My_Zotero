
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2308.12035

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 23 Aug 2023]
Title: RefEgo: Referring Expression Comprehension Dataset from First-Person Perception of Ego4D
Authors: Shuhei Kurita , Naoki Katsura , Eri Onami
Download a PDF of the paper titled RefEgo: Referring Expression Comprehension Dataset from First-Person Perception of Ego4D, by Shuhei Kurita and 2 other authors
Download PDF

    Abstract: Grounding textual expressions on scene objects from first-person views is a truly demanding capability in developing agents that are aware of their surroundings and behave following intuitive text instructions. Such capability is of necessity for glass-devices or autonomous robots to localize referred objects in the real-world. In the conventional referring expression comprehension tasks of images, however, datasets are mostly constructed based on the web-crawled data and don't reflect diverse real-world structures on the task of grounding textual expressions in diverse objects in the real world. Recently, a massive-scale egocentric video dataset of Ego4D was proposed. Ego4D covers around the world diverse real-world scenes including numerous indoor and outdoor situations such as shopping, cooking, walking, talking, manufacturing, etc. Based on egocentric videos of Ego4D, we constructed a broad coverage of the video-based referring expression comprehension dataset: RefEgo. Our dataset includes more than 12k video clips and 41 hours for video-based referring expression comprehension annotation. In experiments, we combine the state-of-the-art 2D referring expression comprehension models with the object tracking algorithm, achieving the video-wise referred object tracking even in difficult conditions: the referred object becomes out-of-frame in the middle of the video or multiple similar objects are presented in the video. 

Comments: 	15 pages, 11 figures. ICCV2023
Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2308.12035 [cs.CV]
  	(or arXiv:2308.12035v1 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2308.12035
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Shuhei Kurita [ view email ]
[v1] Wed, 23 Aug 2023 09:49:20 UTC (33,070 KB)
Full-text links:
Download:

    Download a PDF of the paper titled RefEgo: Referring Expression Comprehension Dataset from First-Person Perception of Ego4D, by Shuhei Kurita and 2 other authors
    PDF
    Other formats 

Current browse context:
cs.CV
< prev   |   next >
new | recent | 2308
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

