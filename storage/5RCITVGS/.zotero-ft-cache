
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2301.12597

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 30 Jan 2023 ( v1 ), last revised 15 Jun 2023 (this version, v3)]
Title: BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models
Authors: Junnan Li , Dongxu Li , Silvio Savarese , Steven Hoi
Download a PDF of the paper titled BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models, by Junnan Li and 3 other authors
Download PDF

    Abstract: The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions. 

Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2301.12597 [cs.CV]
  	(or arXiv:2301.12597v3 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2301.12597
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Junnan Li Dr [ view email ]
[v1] Mon, 30 Jan 2023 00:56:51 UTC (14,779 KB)
[v2] Mon, 1 May 2023 07:30:11 UTC (14,672 KB)
[v3] Thu, 15 Jun 2023 07:57:29 UTC (14,780 KB)
Full-text links:
Download:

    Download a PDF of the paper titled BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models, by Junnan Li and 3 other authors
    PDF
    Other formats 

Current browse context:
cs.CV
< prev   |   next >
new | recent | 2301
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

