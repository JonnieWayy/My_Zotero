
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2309.00616

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 1 Sep 2023 ( v1 ), last revised 4 Sep 2023 (this version, v2)]
Title: OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation
Authors: Zhening Huang , Xiaoyang Wu , Xi Chen , Hengshuang Zhao , Lei Zhu , Joan Lasenby
Download a PDF of the paper titled OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation, by Zhening Huang and 5 other authors
Download PDF

    Abstract: Current 3D open-vocabulary scene understanding methods mostly utilize well-aligned 2D images as the bridge to learn 3D features with language. However, applying these approaches becomes challenging in scenarios where 2D images are absent. In this work, we introduce a completely new pipeline, namely, OpenIns3D, which requires no 2D image inputs, for 3D open-vocabulary scene understanding at the instance level. The OpenIns3D framework employs a "Mask-Snap-Lookup" scheme. The "Mask" module learns class-agnostic mask proposals in 3D point clouds. The "Snap" module generates synthetic scene-level images at multiple scales and leverages 2D vision language models to extract interesting objects. The "Lookup" module searches through the outcomes of "Snap" with the help of Mask2Pixel maps, which contain the precise correspondence between 3D masks and synthetic images, to assign category names to the proposed masks. This 2D input-free, easy-to-train, and flexible approach achieved state-of-the-art results on a wide range of indoor and outdoor datasets with a large margin. Furthermore, OpenIns3D allows for effortless switching of 2D detectors without re-training. When integrated with state-of-the-art 2D open-world models such as ODISE and GroundingDINO, superb results are observed on open-vocabulary instance segmentation. When integrated with LLM-powered 2D models like LISA, it demonstrates a remarkable capacity to process highly complex text queries, including those that require intricate reasoning and world knowledge. Project page: this https URL 

Comments: 	24 pages, 16 figures, 13 tables. Project page: this https URL
Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2309.00616 [cs.CV]
  	(or arXiv:2309.00616v2 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2309.00616
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zhening Huang [ view email ]
[v1] Fri, 1 Sep 2023 17:59:56 UTC (26,885 KB)
[v2] Mon, 4 Sep 2023 17:59:54 UTC (26,885 KB)
Full-text links:
Download:

    Download a PDF of the paper titled OpenIns3D: Snap and Lookup for 3D Open-vocabulary Instance Segmentation, by Zhening Huang and 5 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CV
< prev   |   next >
new | recent | 2309
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

