
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2303.04998

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 9 Mar 2023]
Title: Rethinking Visual Prompt Learning as Masked Visual Token Modeling
Authors: Ning Liao , Bowen Shi , Min Cao , Xiaopeng Zhang , Qi Tian , Junchi Yan
Download a PDF of the paper titled Rethinking Visual Prompt Learning as Masked Visual Token Modeling, by Ning Liao and 5 other authors
Download PDF

    Abstract: Prompt learning has achieved great success in efficiently exploiting large-scale pre-trained models in natural language processing (NLP). It reformulates the downstream tasks as the generative pre-training ones, thus narrowing down the gap between them and improving the performance stably. However, when transferring it to the vision area, current visual prompt learning methods are all designed on discriminative pre-trained models, and there is also a lack of careful design to unify the forms of pre-training and downstream tasks. To explore prompt learning on the generative pre-trained visual model as well as keeping the task consistency, we propose Visual Prompt learning as masked visual Token Modeling (VPTM) to transform the downstream visual classification into the pre-trained masked visual token prediction. In addition, we develop the prototypical verbalizer for mapping the predicted visual token with implicit semantics to explicit downstream labels. To our best knowledge, VPTM is the first visual prompt method on the generative pre-trained visual model, and the first to achieve consistency between pre-training and downstream visual classification by task reformulation. Experiments show that VPTM outperforms other visual prompt methods and achieves excellent efficiency. Moreover, the task consistency of VPTM contributes to the robustness against prompt location, prompt length and prototype dimension, and could be deployed uniformly. 

Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2303.04998 [cs.CV]
  	(or arXiv:2303.04998v1 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2303.04998
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Ning Liao [ view email ]
[v1] Thu, 9 Mar 2023 02:43:10 UTC (2,924 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Rethinking Visual Prompt Learning as Masked Visual Token Modeling, by Ning Liao and 5 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CV
< prev   |   next >
new | recent | 2303
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

