
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2306.11025

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 19 Jun 2023]
Title: Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting
Authors: Xinli Yu , Zheng Chen , Yuan Ling , Shujing Dong , Zongyi Liu , Yanbin Lu
Download a PDF of the paper titled Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting, by Xinli Yu and 5 other authors
Download PDF

    Abstract: This paper presents a novel study on harnessing Large Language Models' (LLMs) outstanding knowledge and reasoning abilities for explainable financial time series forecasting. The application of machine learning models to financial time series comes with several challenges, including the difficulty in cross-sequence reasoning and inference, the hurdle of incorporating multi-modal signals from historical news, financial knowledge graphs, etc., and the issue of interpreting and explaining the model results. In this paper, we focus on NASDAQ-100 stocks, making use of publicly accessible historical stock price data, company metadata, and historical economic/financial news. We conduct experiments to illustrate the potential of LLMs in offering a unified solution to the aforementioned challenges. Our experiments include trying zero-shot/few-shot inference with GPT-4 and instruction-based fine-tuning with a public LLM model Open LLaMA. We demonstrate our approach outperforms a few baselines, including the widely applied classic ARMA-GARCH model and a gradient-boosting tree model. Through the performance comparison results and a few examples, we find LLMs can make a well-thought decision by reasoning over information from both textual news and price time series and extracting insights, leveraging cross-sequence information, and utilizing the inherent knowledge embedded within the LLM. Additionally, we show that a publicly available LLM such as Open-LLaMA, after fine-tuning, can comprehend the instruction to generate explainable forecasts and achieve reasonable performance, albeit relatively inferior in comparison to GPT-4. 

Subjects: 	Machine Learning (cs.LG) ; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Statistical Finance (q-fin.ST)
ACM  classes: 	F.2.2; I.2.7; I.2.1
Cite as: 	arXiv:2306.11025 [cs.LG]
  	(or arXiv:2306.11025v1 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2306.11025
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zheng Chen [ view email ]
[v1] Mon, 19 Jun 2023 15:42:02 UTC (2,609 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting, by Xinli Yu and 5 other authors
    PDF
    PostScript
    Other formats 

Current browse context:
cs.LG
< prev   |   next >
new | recent | 2306
Change to browse by:
cs
cs.AI
cs.CL
q-fin
q-fin.ST
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

