
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2211.11018

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 20 Nov 2022 ( v1 ), last revised 11 May 2023 (this version, v2)]
Title: MagicVideo: Efficient Video Generation With Latent Diffusion Models
Authors: Daquan Zhou , Weimin Wang , Hanshu Yan , Weiwei Lv , Yizhe Zhu , Jiashi Feng
Download a PDF of the paper titled MagicVideo: Efficient Video Generation With Latent Diffusion Models, by Daquan Zhou and 5 other authors
Download PDF

    Abstract: We present an efficient text-to-video generation framework based on latent diffusion models, termed MagicVideo. MagicVideo can generate smooth video clips that are concordant with the given text descriptions. Due to a novel and efficient 3D U-Net design and modeling video distributions in a low-dimensional space, MagicVideo can synthesize video clips with 256x256 spatial resolution on a single GPU card, which takes around 64x fewer computations than the Video Diffusion Models (VDM) in terms of FLOPs. In specific, unlike existing works that directly train video models in the RGB space, we use a pre-trained VAE to map video clips into a low-dimensional latent space and learn the distribution of videos' latent codes via a diffusion model. Besides, we introduce two new designs to adapt the U-Net denoiser trained on image tasks to video data: a frame-wise lightweight adaptor for the image-to-video distribution adjustment and a directed temporal attention module to capture temporal dependencies across frames. Thus, we can exploit the informative weights of convolution operators from a text-to-image model for accelerating video training. To ameliorate the pixel dithering in the generated videos, we also propose a novel VideoVAE auto-encoder for better RGB reconstruction. We conduct extensive experiments and demonstrate that MagicVideo can generate high-quality video clips with either realistic or imaginary content. Refer to \url{ this https URL } for more examples. 

Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2211.11018 [cs.CV]
  	(or arXiv:2211.11018v2 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2211.11018
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zhou Daquan [ view email ]
[v1] Sun, 20 Nov 2022 16:40:31 UTC (43,531 KB)
[v2] Thu, 11 May 2023 11:23:03 UTC (48,805 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled MagicVideo: Efficient Video Generation With Latent Diffusion Models, by Daquan Zhou and 5 other authors
    Download PDF
    PostScript
    Other Formats 

( view license )
Current browse context:
cs.CV
< prev   |   next >
new | recent | 2211
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

