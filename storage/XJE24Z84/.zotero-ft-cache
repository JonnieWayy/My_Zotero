
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2212.10560

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 20 Dec 2022 ( v1 ), last revised 25 May 2023 (this version, v2)]
Title: Self-Instruct: Aligning Language Models with Self-Generated Instructions
Authors: Yizhong Wang , Yeganeh Kordi , Swaroop Mishra , Alisa Liu , Noah A. Smith , Daniel Khashabi , Hannaneh Hajishirzi
Download a PDF of the paper titled Self-Instruct: Aligning Language Models with Self-Generated Instructions, by Yizhong Wang and 6 other authors
Download PDF

    Abstract: Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. Our code and data are available at this https URL . 

Comments: 	ACL 2023 camera ready, 23 pages, 9 figures, 11 tables
Subjects: 	Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI)
Cite as: 	arXiv:2212.10560 [cs.CL]
  	(or arXiv:2212.10560v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2212.10560
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Yizhong Wang [ view email ]
[v1] Tue, 20 Dec 2022 18:59:19 UTC (4,072 KB)
[v2] Thu, 25 May 2023 23:50:07 UTC (7,954 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Self-Instruct: Aligning Language Models with Self-Generated Instructions, by Yizhong Wang and 6 other authors
    PDF
    Other formats 

Current browse context:
cs.CL
< prev   |   next >
new | recent | 2212
Change to browse by:
cs
cs.AI
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

