
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2211.09233

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 16 Nov 2022]
Title: Prompt Tuning for Parameter-efficient Medical Image Segmentation
Authors: Marc Fischer , Alexander Bartler , Bin Yang
Download a PDF of the paper titled Prompt Tuning for Parameter-efficient Medical Image Segmentation, by Marc Fischer and 2 other authors
Download PDF

    Abstract: Neural networks pre-trained on a self-supervision scheme have become the standard when operating in data rich environments with scarce annotations. As such, fine-tuning a model to a downstream task in a parameter-efficient but effective way, e.g. for a new set of classes in the case of semantic segmentation, is of increasing importance. In this work, we propose and investigate several contributions to achieve a parameter-efficient but effective adaptation for semantic segmentation on two medical imaging datasets. Relying on the recently popularized prompt tuning approach, we provide a prompt-able UNet (PUNet) architecture, that is frozen after pre-training, but adaptable throughout the network by class-dependent learnable prompt tokens. We pre-train this architecture with a dedicated dense self-supervision scheme based on assignments to online generated prototypes (contrastive prototype assignment, CPA) of a student teacher combination alongside a concurrent segmentation loss on a subset of classes. We demonstrate that the resulting neural network model is able to attenuate the gap between fully fine-tuned and parameter-efficiently adapted models on CT imaging datasets. As such, the difference between fully fine-tuned and prompt-tuned variants amounts to only 3.83 pp for the TCIA/BTCV dataset and 2.67 pp for the CT-ORG dataset in the mean Dice Similarity Coefficient (DSC, in %) while only prompt tokens, corresponding to 0.85% of the pre-trained backbone model with 6.8M frozen parameters, are adjusted. The code for this work is available on this https URL . 

Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2211.09233 [cs.CV]
  	(or arXiv:2211.09233v1 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2211.09233
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Marc Fischer [ view email ]
[v1] Wed, 16 Nov 2022 21:55:05 UTC (1,820 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Prompt Tuning for Parameter-efficient Medical Image Segmentation, by Marc Fischer and 2 other authors
    PDF
    Other formats 

Current browse context:
cs.CV
< prev   |   next >
new | recent | 2211
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

