
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2305.06524

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 11 May 2023 ( v1 ), last revised 12 May 2023 (this version, v2)]
Title: Can SAM Boost Video Super-Resolution?
Authors: Zhihe Lu , Zeyu Xiao , Jiawang Bai , Zhiwei Xiong , Xinchao Wang
Download a PDF of the paper titled Can SAM Boost Video Super-Resolution?, by Zhihe Lu and 4 other authors
Download PDF

    Abstract: The primary challenge in video super-resolution (VSR) is to handle large motions in the input frames, which makes it difficult to accurately aggregate information from multiple frames. Existing works either adopt deformable convolutions or estimate optical flow as a prior to establish correspondences between frames for the effective alignment and fusion. However, they fail to take into account the valuable semantic information that can greatly enhance it; and flow-based methods heavily rely on the accuracy of a flow estimate model, which may not provide precise flows given two low-resolution frames.
    In this paper, we investigate a more robust and semantic-aware prior for enhanced VSR by utilizing the Segment Anything Model (SAM), a powerful foundational model that is less susceptible to image degradation. To use the SAM-based prior, we propose a simple yet effective module -- SAM-guidEd refinEment Module (SEEM), which can enhance both alignment and fusion procedures by the utilization of semantic information. This light-weight plug-in module is specifically designed to not only leverage the attention mechanism for the generation of semantic-aware feature but also be easily and seamlessly integrated into existing methods. Concretely, we apply our SEEM to two representative methods, EDVR and BasicVSR, resulting in consistently improved performance with minimal implementation effort, on three widely used VSR datasets: Vimeo-90K, REDS and Vid4. More importantly, we found that the proposed SEEM can advance the existing methods in an efficient tuning manner, providing increased flexibility in adjusting the balance between performance and the number of training parameters. Code will be open-source soon. 

Comments: 	Technical Report
Subjects: 	Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2305.06524 [cs.CV]
  	(or arXiv:2305.06524v2 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2305.06524
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Zhihe Lu [ view email ]
[v1] Thu, 11 May 2023 02:02:53 UTC (1,169 KB)
[v2] Fri, 12 May 2023 01:43:00 UTC (1,169 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Can SAM Boost Video Super-Resolution?, by Zhihe Lu and 4 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CV
< prev   |   next >
new | recent | 2305
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

