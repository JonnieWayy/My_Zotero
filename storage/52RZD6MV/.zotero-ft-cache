
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2210.09292

Help | Advanced Search
Search
Computer Science > Computer Vision and Pattern Recognition
(cs)
[Submitted on 7 Oct 2022 ( v1 ), last revised 20 Oct 2022 (this version, v2)]
Title: Efficient Diffusion Models for Vision: A Survey
Authors: Anwaar Ulhaq , Naveed Akhtar , Ganna Pogrebna
Download a PDF of the paper titled Efficient Diffusion Models for Vision: A Survey, by Anwaar Ulhaq and 2 other authors
Download PDF

    Abstract: Diffusion Models (DMs) have demonstrated state-of-the-art performance in content generation without requiring adversarial training. These models are trained using a two-step process. First, a forward - diffusion - process gradually adds noise to a datum (usually an image). Then, a backward - reverse diffusion - process gradually removes the noise to turn it into a sample of the target distribution being modelled. DMs are inspired by non-equilibrium thermodynamics and have inherent high computational complexity. Due to the frequent function evaluations and gradient calculations in high-dimensional spaces, these models incur considerable computational overhead during both training and inference stages. This can not only preclude the democratization of diffusion-based modelling, but also hinder the adaption of diffusion models in real-life applications. Not to mention, the efficiency of computational models is fast becoming a significant concern due to excessive energy consumption and environmental scares. These factors have led to multiple contributions in the literature that focus on devising computationally efficient DMs. In this review, we present the most recent advances in diffusion models for vision, specifically focusing on the important design aspects that affect the computational efficiency of DMs. In particular, we emphasize the recently proposed design choices that have led to more efficient DMs. Unlike the other recent reviews, which discuss diffusion models from a broad perspective, this survey is aimed at pushing this research direction forward by highlighting the design strategies in the literature that are resulting in practicable models for the broader research community. We also provide a future outlook of diffusion models in vision from their computational efficiency viewpoint. 

Comments: 	14 Pages, 5 Figures (in progress)
Subjects: 	Computer Vision and Pattern Recognition (cs.CV) ; Artificial Intelligence (cs.AI)
Cite as: 	arXiv:2210.09292 [cs.CV]
  	(or arXiv:2210.09292v2 [cs.CV] for this version)
  	https://doi.org/10.48550/arXiv.2210.09292
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Anwaar Ulhaq Dr [ view email ]
[v1] Fri, 7 Oct 2022 06:46:13 UTC (1,960 KB)
[v2] Thu, 20 Oct 2022 12:29:30 UTC (3,839 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Efficient Diffusion Models for Vision: A Survey, by Anwaar Ulhaq and 2 other authors
    PDF
    Other formats 

Current browse context:
cs.CV
< prev   |   next >
new | recent | 2210
Change to browse by:
cs
cs.AI
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

